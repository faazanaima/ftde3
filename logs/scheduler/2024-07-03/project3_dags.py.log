[2024-07-03T17:55:08.603+0000] {processor.py:161} INFO - Started process (PID=39) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T17:55:08.605+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T17:55:08.608+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:55:08.608+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:55:08.664+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:55:08.655+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 165, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T17:55:08.665+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:55:08.697+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.100 seconds
[2024-07-03T17:55:39.051+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T17:55:39.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T17:55:39.057+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:55:39.057+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:55:39.104+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:55:39.094+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 165, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T17:55:39.105+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:55:39.132+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.089 seconds
[2024-07-03T17:56:09.310+0000] {processor.py:161} INFO - Started process (PID=155) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T17:56:09.312+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T17:56:09.315+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:56:09.314+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:56:09.352+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:56:09.343+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 165, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T17:56:09.354+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:56:09.379+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.076 seconds
[2024-07-03T17:56:40.225+0000] {processor.py:161} INFO - Started process (PID=213) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T17:56:40.228+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T17:56:40.232+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:56:40.231+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:56:40.270+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:56:40.262+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 165, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T17:56:40.272+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:56:40.294+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.082 seconds
[2024-07-03T17:57:10.836+0000] {processor.py:161} INFO - Started process (PID=271) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T17:57:10.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T17:57:10.839+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:57:10.838+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:57:10.878+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:57:10.871+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 165, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T17:57:10.880+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:57:10.901+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.071 seconds
[2024-07-03T17:57:41.023+0000] {processor.py:161} INFO - Started process (PID=329) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T17:57:41.025+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T17:57:41.026+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:57:41.026+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:57:41.070+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:57:41.058+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 165, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T17:57:41.071+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:57:41.094+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.077 seconds
[2024-07-03T17:58:11.291+0000] {processor.py:161} INFO - Started process (PID=387) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T17:58:11.292+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T17:58:11.294+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:58:11.294+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:58:11.338+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:58:11.329+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 165, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T17:58:11.339+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:58:11.361+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.077 seconds
[2024-07-03T17:58:41.639+0000] {processor.py:161} INFO - Started process (PID=445) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T17:58:41.640+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T17:58:41.642+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:58:41.642+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:58:41.679+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:58:41.671+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 165, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T17:58:41.681+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:58:41.703+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.070 seconds
[2024-07-03T17:59:11.851+0000] {processor.py:161} INFO - Started process (PID=503) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T17:59:11.852+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T17:59:11.854+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:59:11.853+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:59:11.898+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:59:11.888+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 165, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T17:59:11.899+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:59:11.922+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.078 seconds
[2024-07-03T17:59:20.230+0000] {processor.py:161} INFO - Started process (PID=555) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T17:59:20.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T17:59:20.233+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:59:20.233+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:59:20.294+0000] {logging_mixin.py:188} INFO - [2024-07-03T17:59:20.285+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T17:59:20.295+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T17:59:20.323+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.100 seconds
[2024-07-03T18:00:12.577+0000] {processor.py:161} INFO - Started process (PID=39) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:00:12.579+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:00:12.583+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:00:12.582+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:00:12.629+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:00:12.619+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:00:12.631+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:00:12.657+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.087 seconds
[2024-07-03T18:00:43.653+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:00:43.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:00:43.658+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:00:43.657+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:00:43.692+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:00:43.684+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:00:43.694+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:00:43.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.074 seconds
[2024-07-03T18:01:14.472+0000] {processor.py:161} INFO - Started process (PID=155) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:01:14.473+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:01:14.475+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:01:14.474+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:01:14.528+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:01:14.520+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:01:14.530+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:01:14.549+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.083 seconds
[2024-07-03T18:01:44.995+0000] {processor.py:161} INFO - Started process (PID=213) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:01:44.996+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:01:44.998+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:01:44.997+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:01:45.036+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:01:45.028+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:01:45.038+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:01:45.061+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.073 seconds
[2024-07-03T18:02:15.782+0000] {processor.py:161} INFO - Started process (PID=271) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:02:15.784+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:02:15.785+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:02:15.785+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:02:15.825+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:02:15.817+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:02:15.827+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:02:15.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.079 seconds
[2024-07-03T18:02:45.955+0000] {processor.py:161} INFO - Started process (PID=329) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:02:45.956+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:02:45.957+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:02:45.957+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:02:45.995+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:02:45.984+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:02:45.996+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:02:46.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.069 seconds
[2024-07-03T18:03:16.995+0000] {processor.py:161} INFO - Started process (PID=387) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:03:16.999+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:03:17.001+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:03:17.001+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:03:17.039+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:03:17.030+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:03:17.041+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:03:17.063+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.084 seconds
[2024-07-03T18:03:18.224+0000] {processor.py:161} INFO - Started process (PID=397) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:03:18.225+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:03:18.227+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:03:18.227+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:03:18.312+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:03:18.300+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:03:18.315+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:03:18.358+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.147 seconds
[2024-07-03T18:03:49.076+0000] {processor.py:161} INFO - Started process (PID=452) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:03:49.078+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:03:49.079+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:03:49.079+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:03:49.129+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:03:49.119+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:03:49.130+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:03:49.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.082 seconds
[2024-07-03T18:04:19.276+0000] {processor.py:161} INFO - Started process (PID=510) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:04:19.277+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:04:19.279+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:04:19.278+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:04:19.322+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:04:19.313+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:04:19.323+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:04:19.344+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.074 seconds
[2024-07-03T18:04:50.131+0000] {processor.py:161} INFO - Started process (PID=568) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:04:50.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:04:50.134+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:04:50.134+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:04:50.168+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:04:50.161+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:04:50.169+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:04:50.189+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.065 seconds
[2024-07-03T18:05:21.015+0000] {processor.py:161} INFO - Started process (PID=626) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:05:21.016+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:05:21.017+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:05:21.017+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:05:21.056+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:05:21.049+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:05:21.057+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:05:21.077+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.069 seconds
[2024-07-03T18:05:51.210+0000] {processor.py:161} INFO - Started process (PID=684) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:05:51.212+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:05:51.214+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:05:51.213+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:05:51.253+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:05:51.245+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:05:51.255+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:05:51.274+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.072 seconds
[2024-07-03T18:06:21.537+0000] {processor.py:161} INFO - Started process (PID=742) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:06:21.539+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:06:21.541+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:06:21.541+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:06:21.588+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:06:21.579+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:06:21.590+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:06:21.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.087 seconds
[2024-07-03T18:06:52.213+0000] {processor.py:161} INFO - Started process (PID=800) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:06:52.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:06:52.216+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:06:52.215+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:06:52.261+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:06:52.252+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:06:52.262+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:06:52.282+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.076 seconds
[2024-07-03T18:07:22.501+0000] {processor.py:161} INFO - Started process (PID=858) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:07:22.502+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:07:22.504+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:07:22.503+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:07:22.534+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:07:22.526+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:07:22.535+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:07:22.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.056 seconds
[2024-07-03T18:07:53.522+0000] {processor.py:161} INFO - Started process (PID=916) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:07:53.523+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:07:53.525+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:07:53.525+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:07:53.566+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:07:53.558+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:07:53.568+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:07:53.590+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.076 seconds
[2024-07-03T18:08:23.793+0000] {processor.py:161} INFO - Started process (PID=974) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:08:23.796+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:08:23.799+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:08:23.798+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:08:23.852+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:08:23.840+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:08:23.854+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:08:23.880+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.099 seconds
[2024-07-03T18:08:54.264+0000] {processor.py:161} INFO - Started process (PID=1032) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:08:54.266+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:08:54.268+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:08:54.267+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:08:54.303+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:08:54.296+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:08:54.304+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:08:54.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.072 seconds
[2024-07-03T18:09:24.554+0000] {processor.py:161} INFO - Started process (PID=1090) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:09:24.557+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:09:24.560+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:09:24.559+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:09:24.602+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:09:24.595+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:09:24.603+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:09:24.621+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.081 seconds
[2024-07-03T18:09:54.816+0000] {processor.py:161} INFO - Started process (PID=1148) to work on /opt/airflow/dags/project3_dags.py
[2024-07-03T18:09:54.819+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/project3_dags.py for tasks to queue
[2024-07-03T18:09:54.821+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:09:54.820+0000] {dagbag.py:545} INFO - Filling up the DagBag from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:09:54.867+0000] {logging_mixin.py:188} INFO - [2024-07-03T18:09:54.860+0000] {dagbag.py:355} ERROR - Failed to import: /opt/airflow/dags/project3_dags.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 351, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/project3_dags.py", line 161, in <module>
    save_to_gcs = PostgresToGCSOperator(
                  ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 485, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/google/cloud/transfers/postgres_to_gcs.py", line 111, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 468, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2024-07-03T18:09:54.869+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/project3_dags.py
[2024-07-03T18:09:54.892+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/project3_dags.py took 0.087 seconds
